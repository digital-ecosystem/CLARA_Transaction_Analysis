# Code vs. Dokumentation Vergleich

## Datum: 2025-01-12

---

## âŒ **KRITISCHES PROBLEM: Predictability-Analyse fehlt komplett!**

### Dokumentation sagt:
- **Vier Analyseebenen:**
  1. Weight-Analyse (Anti-Smurfing) - 40% Gewichtung
  2. Entropie-Analyse (VerhaltenskomplexitÃ¤t) - 25% Gewichtung
  3. **Predictability-Analyse (VerhaltensstabilitÃ¤t) - 25% Gewichtung** âš ï¸
  4. Statistische Methoden - 10% Gewichtung

### Code zeigt:
- **Nur drei Analyseebenen:**
  1. Weight-Analyse - 40% Gewichtung âœ…
  2. Entropie-Analyse - 30% Gewichtung âš ï¸ (sollte 25% sein)
  3. **Predictability-Analyse - FEHLT KOMPLETT!** âŒ
  4. Statistische Methoden - 30% Gewichtung âš ï¸ (sollte 10% sein)

**Aktuelle Gewichtung im Code:**
```python
# analyzer.py, Zeile 234-239
if name == 'weight':
    weighted_points += 0.40 * suspicion_net  # âœ… KORREKT
elif name == 'entropy':
    weighted_points += 0.30 * suspicion_net  # âŒ SOLLTE 0.25 SEIN
elif name == 'statistics':
    weighted_points += 0.30 * suspicion_net  # âŒ SOLLTE 0.10 SEIN
# Predictability fehlt komplett! âŒ
```

**Sollte sein (laut Dokumentation):**
```python
if name == 'weight':
    weighted_points += 0.40 * suspicion_net  # 40%
elif name == 'entropy':
    weighted_points += 0.25 * suspicion_net  # 25%
elif name == 'predictability':
    weighted_points += 0.25 * suspicion_net  # 25% - FEHLT!
elif name == 'statistics':
    weighted_points += 0.10 * suspicion_net  # 10%
```

---

## ðŸ“Š **Detaillierter Vergleich**

### 1. Gewichtung der Module

| Modul | Dokumentation | Code | Status |
|-------|---------------|------|--------|
| Weight | 40% | 40% | âœ… KORREKT |
| Entropie | 25% | 30% | âŒ FALSCH (sollte 25% sein) |
| **Predictability** | **25%** | **0% (FEHLT!)** | âŒ **KRITISCH** |
| Statistik | 10% | 30% | âŒ FALSCH (sollte 10% sein) |

**Problem:** Die fehlende Predictability-Gewichtung (25%) wurde auf Entropie (+5%) und Statistik (+20%) verteilt.

---

### 2. Multiplikatoren (Âµ)

| Modul | Dokumentation | Code | Status |
|-------|---------------|------|--------|
| Weight | Âµ = 2.0 | Âµ = 2.0 | âœ… KORREKT |
| Entropie | Âµ = 1.2 | Âµ = 1.2 | âœ… KORREKT |
| **Predictability** | **Âµ = 1.0** | **FEHLT!** | âŒ **KRITISCH** |
| Statistik | Âµ = 1.5 | Âµ = 1.5 | âœ… KORREKT |

**Code (analyzer.py, Zeile 402-452):**
```python
points['weight'] = ModulePoints(
    trust_points=weight_tp,
    suspicion_points=weight_sp,
    multiplier=2.0  # âœ… KORREKT
)

points['entropy'] = ModulePoints(
    trust_points=entropy_tp,
    suspicion_points=entropy_sp,
    multiplier=1.2  # âœ… KORREKT
)

# Predictability fehlt komplett! âŒ

points['statistics'] = ModulePoints(
    trust_points=stats_tp,
    suspicion_points=stats_sp,
    multiplier=1.5  # âœ… KORREKT
)
```

---

### 3. Aggregationsformel

**Dokumentation:**
```
Gesamtpunkte = (W Ã— 0.40) + (E Ã— 0.25) + (P Ã— 0.25) + (S Ã— 0.10)
```

**Code (analyzer.py, Zeile 224-239):**
```python
# FEHLT: Predictability (P Ã— 0.25)
weighted_points = 0.0
for name, points in module_points.items():
    if name == 'trust':
        continue  # Trust_Score entfernt (OK)
    
    suspicion_net = (points.suspicion_points - points.trust_points) * points.multiplier
    
    if name == 'weight':
        weighted_points += 0.40 * suspicion_net  # âœ…
    elif name == 'entropy':
        weighted_points += 0.30 * suspicion_net  # âŒ SOLLTE 0.25 SEIN
    elif name == 'statistics':
        weighted_points += 0.30 * suspicion_net  # âŒ SOLLTE 0.10 SEIN
    # FEHLT: Predictability! âŒ
```

---

### 4. VerstÃ¤rkungsfaktor

**Dokumentation:**
```
v = 1 + 0.1 Ã— (n_Module - 1)
Maximal 30% VerstÃ¤rkung
```

**Code (analyzer.py, Zeile 476-480):**
```python
if n_modules > 1:
    v = 1.0 + 0.1 * (n_modules - 1)
    # Maximal 30% VerstÃ¤rkung
    v = min(v, 1.3)
else:
    v = 1.0
```

**Status:** âœ… **KORREKT**

---

### 5. Absolute (70%) + Relative (30%) Aufteilung

**Dokumentation:**
- Absolute Komponenten: 70%
- Relative Komponenten: 30%

**Code (analyzer.py, Zeile 248, 264):**
```python
absolute_score = weighted_points * amplification_factor * 0.7  # âœ… 70%
# ...
total_points = absolute_score + relative_score_sp * 0.3  # âœ… 30%
```

**Status:** âœ… **KORREKT**

---

### 6. Risikozonen (Suspicion Points)

**Dokumentation:**
| Suspicion Points | Risikostufe |
|-----------------|-------------|
| 0 â€“ 150 | UnauffÃ¤llig (GREEN) |
| 150 â€“ 300 | Leichte AuffÃ¤lligkeit (YELLOW) |
| 300 â€“ 500 | ErhÃ¶htes Risiko (ORANGE) |
| 500 â€“ 1000+ | Hoher Verdacht (RED) |

**Code (analyzer.py, Zeile 551-558):**
```python
if suspicion_score < 150:  # GREEN
    return RiskLevel.GREEN
elif suspicion_score < 300:  # YELLOW
    return RiskLevel.YELLOW
elif suspicion_score < 500:  # ORANGE
    return RiskLevel.ORANGE
else:  # RED (>= 500)
    return RiskLevel.RED
```

**Status:** âœ… **KORREKT**

---

### 7. Nichtlineare Skalierung

**Dokumentation:**
- 0-150 SP: Linear
- 150-300 SP: Progressiv (1.2x)
- 300-500 SP: Progressiv (1.5x)
- 500+ SP: DÃ¤mpfung (logarithmisch)

**Code (analyzer.py, Zeile 514-528):**
```python
if abs_points <= 150:
    scaled = abs_points  # Linear
elif abs_points <= 300:
    scaled = 150 + (abs_points - 150) * 1.2  # Progressiv 1.2x
elif abs_points <= 500:
    scaled = 150 + 150 * 1.2 + (abs_points - 300) * 1.5  # Progressiv 1.5x
else:
    excess = abs_points - 500
    scaled = 150 + 150 * 1.2 + 200 * 1.5 + excess * 0.8  # DÃ¤mpfung
```

**Status:** âœ… **KORREKT**

---

### 8. Predictability-Analyse - Was fehlt?

**Dokumentation beschreibt:**

**Analysebereiche:**
1. **Zeitliche StabilitÃ¤t** - Konstanz der zeitlichen AbstÃ¤nde zwischen Transaktionen
2. **Betrags-Konsistenz** - Gleichbleibende Betragsmuster Ã¼ber Zeit
3. **Kanal-KontinuitÃ¤t** - Wiederkehrende Nutzung etablierter KanÃ¤le
4. **Ziel-StabilitÃ¤t** - Konstanz der EmpfÃ¤nger und Gegenparteien

**Bewertungslogik:**
- Kurzfristig (30 Tage): spontane oder abrupte Ã„nderungen
- Mittelfristig (90 Tage): saisonale oder zyklische Schwankungen
- Langfristig (180 Tage): strukturelle StabilitÃ¤t

**Punkteverteilung:**
- **Trust Points (TP):**
  - Hohe Predictability (T â‰¥ 0.8) â†’ +150 TP
  - Langfristig konstante Frequenz innerhalb SoF-Rahmens â†’ +80 TP
- **Suspicion Points (SP):**
  - Instabiles Verhalten â†’ -150 SP

**Multiplikator:** Âµ = 1.0

**Gewichtung:** 25% (zusammen mit Entropie)

---

## ðŸ” **Zusammenfassung der Probleme**

### âŒ **KRITISCH:**
1. **Predictability-Analyse fehlt komplett** - 25% Gewichtung fehlt
2. **Entropie-Gewichtung falsch** - 30% statt 25%
3. **Statistik-Gewichtung falsch** - 30% statt 10%

### âœ… **KORREKT:**
1. Weight-Gewichtung (40%)
2. Multiplikatoren (Weight 2.0, Entropie 1.2, Statistik 1.5)
3. VerstÃ¤rkungsfaktor (v = 1 + 0.1 Ã— (n-1))
4. Absolute (70%) + Relative (30%) Aufteilung
5. Risikozonen (150/300/500)
6. Nichtlineare Skalierung

---

## ðŸŽ¯ **Empfohlene MaÃŸnahmen**

1. **Predictability-Analyse implementieren:**
   - Neues Modul `predictability_detector.py` erstellen
   - Analysebereiche: Zeitliche StabilitÃ¤t, Betrags-Konsistenz, Kanal-KontinuitÃ¤t, Ziel-StabilitÃ¤t
   - TP/SP System: +150 TP bei hoher Predictability, -150 SP bei InstabilitÃ¤t
   - Multiplikator: Âµ = 1.0
   - Gewichtung: 25%

2. **Gewichtungen korrigieren:**
   - Entropie: 30% â†’ 25%
   - Predictability: 0% â†’ 25% (neu)
   - Statistik: 30% â†’ 10%

3. **Aggregationsformel korrigieren:**
   ```python
   weighted_points = (
       0.40 * weight_suspicion_net +
       0.25 * entropy_suspicion_net +
       0.25 * predictability_suspicion_net +  # NEU
       0.10 * statistics_suspicion_net
   )
   ```

---

**Stand:** 2025-01-12  
**Status:** Code entspricht NICHT vollstÃ¤ndig der Dokumentation - Predictability-Analyse fehlt!

