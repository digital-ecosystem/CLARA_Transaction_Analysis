# Diskrepanz-Analyse: Dokumentation vs. Implementierung

## Datum: 2025-11-12

---

## üî¥ **KRITISCHE UNTERSCHIEDE**

### 1. **Nur 88 Kunden analysiert (statt 246)**

**Ursache:** Die API analysiert nur Kunden, die im `transaction_history` des Analyzers gespeichert sind. Aber nicht alle Kunden aus der CSV haben Transaktionen, die erfolgreich geparst wurden.

**Problem:** Viele Kunden-IDs tauchen in der CSV auf, aber deren Transaktionen werden nicht dem Analyzer hinzugef√ºgt.

---

### 2. **Punktevergabe zu niedrig**

| Metrik | **Aktuell** | **Dokumentation** | **Faktor** |
|--------|-------------|-------------------|------------|
| Max Score | 1.31 ‚Üí 6.55* | 14.48 | ~2.2x zu niedrig |
| Typischer SP-Bereich | 0-100 | 0-1000+ | ~10x zu niedrig |

*Nach `/10` Anpassung (vorher `/50`)

---

## üìã **DOKUMENTATION SAGT:**

### Punktebereiche (laut Dokumentation)

```
0 ‚Äì 150 SP     ‚Üí Unauff√§llig
150 ‚Äì 300 SP   ‚Üí Leichte Auff√§lligkeit  
300 ‚Äì 500 SP   ‚Üí Erh√∂htes Risiko
500 ‚Äì 1000+ SP ‚Üí Hoher Verdacht
```

### Multiplikatoren (laut Dokumentation)

| Modul | ¬µ | Typischer Punktebereich |
|-------|---|-------------------------|
| Weight | 2.0 | 0 ‚Äì 1000 SP |
| Entropie | 1.2 | -200 TP ‚Ä¶ +400 SP |
| Predictability | 1.0 | -150 SP ‚Ä¶ +300 TP |
| Statistik | 1.5 | 0 ‚Äì 500 SP |

### Beispiel aus Dokumentation:

**Smurfing-Kunde:**
- Threshold Avoidance ‚â• 0.5 ‚Üí +300 SP
- High Temporal Density (>5 Tx/Woche) ‚Üí +400 SP
- Cumulative Large Amount ‚â• 50k ‚Üí +150 SP
- **SUMME Weight-Modul:** ~850 SP
- **Mit ¬µ=2.0:** 850 √ó 2.0 = **1,700 Punkte**
- **Gewichtet (40%):** 1,700 √ó 0.40 = **680**
- **Mit Verst√§rkung (v=1.2):** 680 √ó 1.2 = **816**
- **Mit 0.7:** 816 √ó 0.7 = **571**
- **Skaliert:** ~720 (nichtlinear)
- **Final Score:** 720 / 10 = **72 (!)**

---

## üìä **AKTUELLE IMPLEMENTIERUNG**

### Was der Code macht:

```python
# calculate_module_points() - Zeile 356-462
if weight_analysis.is_suspicious:
    if weight_analysis.threshold_avoidance_ratio >= 0.5:
        weight_sp += 300  # ‚úÖ RICHTIG
    if weight_analysis.cumulative_large_amount >= 50000:
        weight_sp += 150  # ‚úÖ RICHTIG
    if weight_analysis.temporal_density_weeks > 5.0:
        weight_sp += 400  # ‚úÖ RICHTIG
```

**Das sieht korrekt aus!** Aber...

### Das Problem ist die finale Skalierung:

```python
# Zeile 261 (nach meiner √Ñnderung)
suspicion_score = scaled_points / 10.0  # War /50.0
```

**Aber laut Dokumentation sollte es sein:**
- Keine Division, sondern direkte √úbertragung!
- Oder: Division durch kleineren Wert (z.B. /5.0)

---

## üîç **WARUM NUR 88 KUNDEN?**

Die CSV enth√§lt 246 eindeutige Kunden, aber nur 88 werden analysiert.

**M√∂gliche Ursachen:**
1. Parse-Fehler bei bestimmten Transaktionen
2. Kunden ohne g√ºltige Transaktionen
3. Timestamp-Probleme
4. Filter-Logic schlie√üt Kunden aus

**Log zeigt:**
```
4157 Transaktionen erfolgreich geparst
88 Kunden analysiert
```

Das bedeutet: **4157 Transaktionen verteilen sich auf nur 88 Kunden** (Durchschnitt: ~47 Tx/Kunde)

---

## ‚úÖ **L√ñSUNGEN**

### 1. Skalierung korrigieren

**Option A:** Keine Division (direkt als Score 0-100+)
```python
suspicion_score = scaled_points  # Direkt
```

**Option B:** Kleinerer Divisor
```python
suspicion_score = scaled_points / 5.0  # Statt /10
```

### 2. Kunden-Analyse debuggen

Pr√ºfen, warum nur 88 von 246 Kunden analysiert werden:
- Sind alle Transaktionen korrekt geparst?
- Werden alle Kunden-IDs erkannt?
- Gibt es Filter, die Kunden ausschlie√üen?

### 3. Risk Level Schwellen anpassen

**Aktuell:**
```python
if suspicion_score < 1.0: return RiskLevel.GREEN
elif suspicion_score < 2.0: return RiskLevel.YELLOW
elif suspicion_score < 3.0: return RiskLevel.ORANGE
else: return RiskLevel.RED
```

**Laut Dokumentation (nach Skalierung):**
```python
if suspicion_score < 2.0: return RiskLevel.GREEN
elif suspicion_score < 4.0: return RiskLevel.YELLOW
elif suspicion_score < 8.0: return RiskLevel.ORANGE
else: return RiskLevel.RED
```

---

## üìå **EMPFEHLUNG**

1. **Sofort:** Skalierung von `/10` auf `/5` √§ndern
2. **Sofort:** Risk Level Schwellen verdoppeln
3. **Debug:** Pr√ºfen, warum nur 88 Kunden
4. **Test:** Mit echter problematischer CSV testen

---

## üéØ **ERWARTETE VERBESSERUNG**

| Metrik | **Aktuell** | **Nach Fix** |
|--------|-------------|--------------|
| Max Score | ~6.5 | ~13-15 |
| GREEN | 96.3% | ~75-80% |
| RED | 0% | ~5-10% |
| Kunden analysiert | 88 | 246 |

---

**Status:** ‚ö†Ô∏è **KRITISCHE DISKREPANZ IDENTIFIZIERT**

Die Implementierung folgt der Dokumentation in der Punktevergabe, aber die finale Skalierung ist zu stark ged√§mpft.

